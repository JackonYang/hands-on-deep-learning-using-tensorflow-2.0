{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "3 种模型在 2 个数据集上的运行时间 & 正确率数据汇总如下：\n",
    "\n",
    "| 模型 | MNIST 数据集 | CIFAR10 数据集 |\n",
    "| -- | -- | -- |\n",
    "| 单层 softmax | 6s, 92% | 30s, 34% |\n",
    "| 3 层全连接 | / | 57s, 37% |\n",
    "| AlexNet | 8s, 97% | 3min, 70%|\n",
    "\n",
    "观点：\n",
    "\n",
    "1. 单层 softmax 和 3 层全连接，在 cifar10 上性能飞掉，基本不具备实用价值。\n",
    "2. AlexNet 在 cifar10 上展示了 CNN 网络的潜力。70% 的正确率，在容错率较高的场景下，具备一定的使用价值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单层 softmax 模型\n",
    "\n",
    "测试在 MNIST & cifar 数据集上到效果。作为后续测试的基准数据。\n",
    "\n",
    "- timecost: ~6s\n",
    "- accuracy: 92%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 数据集 - 1 Layer softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! start time counting\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 20us/sample - loss: 0.4661 - accuracy: 0.8785\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3040 - accuracy: 0.9154\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2834 - accuracy: 0.9205\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2730 - accuracy: 0.9241\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.2664 - accuracy: 0.9260\n",
      "10000/10000 [==============================] - 0s 15us/sample - loss: 0.2689 - accuracy: 0.9248\n",
      "!! Total timecost: 5.97s\n"
     ]
    }
   ],
   "source": [
    "N, W, H = x_train.shape\n",
    "N_LABELS = 10\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(W, H)),\n",
    "  tf.keras.layers.Dense(N_LABELS, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('!! start time counting')\n",
    "tic = time.time()\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)\n",
    "toc = time.time()\n",
    "print('!! Total timecost: %.2fs' % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 数据集 -- 1 Layer softmax\n",
    "\n",
    "相同的模型，相比于 MNIST 数据集，处理时间从 6s 到 30s，准确率从 92%。\n",
    "\n",
    "模型基本不能用了\n",
    "\n",
    "- timecost: ~30s\n",
    "- accuracy: 34%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! start time counting\n",
      "Train on 50000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 2s 31us/sample - loss: 1.9562 - accuracy: 0.3214\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.8866 - accuracy: 0.3500\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.8544 - accuracy: 0.3636\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.8397 - accuracy: 0.3691\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.8292 - accuracy: 0.3732\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.8289 - accuracy: 0.3747\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.8100 - accuracy: 0.3822\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.8186 - accuracy: 0.3801\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.8018 - accuracy: 0.3849\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.7978 - accuracy: 0.3873\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.7962 - accuracy: 0.3880\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.7924 - accuracy: 0.3904\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.7911 - accuracy: 0.3886\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.7873 - accuracy: 0.3901\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.7795 - accuracy: 0.3936\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.7824 - accuracy: 0.3949\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.7775 - accuracy: 0.3957\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.7804 - accuracy: 0.3960\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.7749 - accuracy: 0.3951\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 1s 29us/sample - loss: 1.7686 - accuracy: 0.3961\n",
      "10000/10000 [==============================] - 0s 22us/sample - loss: 1.9142 - accuracy: 0.3378\n",
      "!! Total timecost: 29.82s\n"
     ]
    }
   ],
   "source": [
    "N, W, H, C = x_train.shape\n",
    "N_LABELS = 10\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(W, H, C)),\n",
    "  tf.keras.layers.Dense(N_LABELS, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('!! start time counting')\n",
    "tic = time.time()\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20)\n",
    "model.evaluate(x_test, y_test)\n",
    "toc = time.time()\n",
    "print('!! Total timecost: %.2fs' % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 层全连接模型\n",
    "\n",
    "只验证在 cifar10 数据集上的效果，即可看出，提升很有限。\n",
    "\n",
    "正确率从 34% 提高到 37%，依旧是不能用的数字。处理时间从 30s 增加到 57s，基本翻倍。\n",
    "\n",
    "- timecost: ~57s\n",
    "- accuracy: 37%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! start time counting\n",
      "Train on 50000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 3s 59us/sample - loss: 1.8808 - accuracy: 0.3087\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.7541 - accuracy: 0.3637\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.7124 - accuracy: 0.3788\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.6888 - accuracy: 0.3879\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.6652 - accuracy: 0.3974\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.6537 - accuracy: 0.4005\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.6454 - accuracy: 0.4057\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.6361 - accuracy: 0.4086\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.6255 - accuracy: 0.4095\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.6211 - accuracy: 0.4121\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.6097 - accuracy: 0.4194\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.6019 - accuracy: 0.4181\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.5981 - accuracy: 0.4195\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.5938 - accuracy: 0.4216\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.5866 - accuracy: 0.4235\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.5866 - accuracy: 0.4229\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.5789 - accuracy: 0.4269\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.5721 - accuracy: 0.4285\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.5733 - accuracy: 0.4269\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 3s 56us/sample - loss: 1.5640 - accuracy: 0.4308\n",
      "10000/10000 [==============================] - 0s 27us/sample - loss: 1.6025 - accuracy: 0.4267\n",
      "!! Total timecost: 57.56s\n"
     ]
    }
   ],
   "source": [
    "N, W, H, C = x_train.shape\n",
    "N_LABELS = 10\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(W, H, C)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(1000, activation='relu'),\n",
    "  tf.keras.layers.Dense(N_LABELS, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('!! start time counting')\n",
    "tic = time.time()\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20)\n",
    "model.evaluate(x_test, y_test)\n",
    "toc = time.time()\n",
    "print('!! Total timecost: %.2fs' % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet -- 简单又经典的入门级 CNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2D in module tensorflow.python.keras.layers.convolutional:\n",
      "\n",
      "class Conv2D(Conv)\n",
      " |  Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  2D convolution layer (e.g. spatial convolution over images).\n",
      " |  \n",
      " |  This layer creates a convolution kernel that is convolved\n",
      " |  with the layer input to produce a tensor of\n",
      " |  outputs. If `use_bias` is True,\n",
      " |  a bias vector is created and added to the outputs. Finally, if\n",
      " |  `activation` is not `None`, it is applied to the outputs as well.\n",
      " |  \n",
      " |  When using this layer as the first layer in a model,\n",
      " |  provide the keyword argument `input_shape`\n",
      " |  (tuple of integers, does not include the sample axis),\n",
      " |  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
      " |  in `data_format=\"channels_last\"`.\n",
      " |  \n",
      " |  Arguments:\n",
      " |    filters: Integer, the dimensionality of the output space\n",
      " |      (i.e. the number of output filters in the convolution).\n",
      " |    kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
      " |      height and width of the 2D convolution window.\n",
      " |      Can be a single integer to specify the same value for\n",
      " |      all spatial dimensions.\n",
      " |    strides: An integer or tuple/list of 2 integers,\n",
      " |      specifying the strides of the convolution along the height and width.\n",
      " |      Can be a single integer to specify the same value for\n",
      " |      all spatial dimensions.\n",
      " |      Specifying any stride value != 1 is incompatible with specifying\n",
      " |      any `dilation_rate` value != 1.\n",
      " |    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      " |    data_format: A string,\n",
      " |      one of `channels_last` (default) or `channels_first`.\n",
      " |      The ordering of the dimensions in the inputs.\n",
      " |      `channels_last` corresponds to inputs with shape\n",
      " |      `(batch, height, width, channels)` while `channels_first`\n",
      " |      corresponds to inputs with shape\n",
      " |      `(batch, channels, height, width)`.\n",
      " |      It defaults to the `image_data_format` value found in your\n",
      " |      Keras config file at `~/.keras/keras.json`.\n",
      " |      If you never set it, then it will be \"channels_last\".\n",
      " |    dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
      " |      the dilation rate to use for dilated convolution.\n",
      " |      Can be a single integer to specify the same value for\n",
      " |      all spatial dimensions.\n",
      " |      Currently, specifying any `dilation_rate` value != 1 is\n",
      " |      incompatible with specifying any stride value != 1.\n",
      " |    activation: Activation function to use.\n",
      " |      If you don't specify anything, no activation is applied\n",
      " |      (ie. \"linear\" activation: `a(x) = x`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      " |    bias_initializer: Initializer for the bias vector.\n",
      " |    kernel_regularizer: Regularizer function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_regularizer: Regularizer function applied to the bias vector.\n",
      " |    activity_regularizer: Regularizer function applied to\n",
      " |      the output of the layer (its \"activation\")..\n",
      " |    kernel_constraint: Constraint function applied to the kernel matrix.\n",
      " |    bias_constraint: Constraint function applied to the bias vector.\n",
      " |  \n",
      " |  Input shape:\n",
      " |    4D tensor with shape:\n",
      " |    `(samples, channels, rows, cols)` if data_format='channels_first'\n",
      " |    or 4D tensor with shape:\n",
      " |    `(samples, rows, cols, channels)` if data_format='channels_last'.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    4D tensor with shape:\n",
      " |    `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n",
      " |    or 4D tensor with shape:\n",
      " |    `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n",
      " |    `rows` and `cols` values might have changed due to padding.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv2D\n",
      " |      Conv\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Conv:\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(layers.Conv2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar 数据集合\n",
    "\n",
    "相比于 3 个全连接层，AlexNet 的准确率从 37% 提高到 70%，接近一倍。处理时间从 1min 到 3min，增加 3 倍。\n",
    "\n",
    "模型的性能，明显提升。达到了有一定使用价值的水平。\n",
    "\n",
    "- timecost: ~188s (3min)\n",
    "- accuracy: 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! start time counting\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s 379us/sample - loss: 1.5137 - accuracy: 0.4511 - val_loss: 1.2534 - val_accuracy: 0.5496\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 1.1523 - accuracy: 0.5938 - val_loss: 1.0748 - val_accuracy: 0.6230\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 1.0124 - accuracy: 0.6428 - val_loss: 0.9973 - val_accuracy: 0.6474\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.9237 - accuracy: 0.6730 - val_loss: 0.9718 - val_accuracy: 0.6590\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.8458 - accuracy: 0.7028 - val_loss: 0.9199 - val_accuracy: 0.6800\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.7895 - accuracy: 0.7238 - val_loss: 0.9056 - val_accuracy: 0.6871\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.7439 - accuracy: 0.7375 - val_loss: 0.8902 - val_accuracy: 0.6958\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 19s 374us/sample - loss: 0.6957 - accuracy: 0.7532 - val_loss: 0.9053 - val_accuracy: 0.6982\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.6492 - accuracy: 0.7718 - val_loss: 0.8657 - val_accuracy: 0.7092\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 19s 374us/sample - loss: 0.6171 - accuracy: 0.7826 - val_loss: 0.8796 - val_accuracy: 0.7051\n",
      "10000/10000 - 1s - loss: 0.8796 - accuracy: 0.7051\n",
      "!! Total timecost: 188.69s\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print('!! start time counting')\n",
    "tic = time.time()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, \n",
    "                    validation_data=(x_test, y_test))\n",
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "toc = time.time()\n",
    "print('!! Total timecost: %.2fs' % (toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 1s - loss: 0.8796 - accuracy: 0.7051\n",
      "0.7051\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train vs evaluate 的 accuracy 曲线\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 数据集合\n",
    "\n",
    "相比于单层 softmax，处理时间从 6s 到 8s，增加 30%，正确率从 92% 到 97%，模型性能提升较为明显。\n",
    "\n",
    "- timecost: ~8s\n",
    "- accuracy: 97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! start time counting\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3978 - accuracy: 0.8825 - val_loss: 0.1686 - val_accuracy: 0.9494\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2269 - accuracy: 0.9331 - val_loss: 0.1241 - val_accuracy: 0.9615\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.1900 - accuracy: 0.9430 - val_loss: 0.1051 - val_accuracy: 0.9677\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.1660 - accuracy: 0.9505 - val_loss: 0.0970 - val_accuracy: 0.9716\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.1513 - accuracy: 0.9539 - val_loss: 0.0905 - val_accuracy: 0.9725\n",
      "10000/10000 - 0s - loss: 0.0905 - accuracy: 0.9725\n",
      "!! Total timecost: 8.09s\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('!! start time counting')\n",
    "tic = time.time()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, \n",
    "                    validation_data=(x_test, y_test))\n",
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "toc = time.time()\n",
    "print('!! Total timecost: %.2fs' % (toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
